{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Neural Operator for 2-Dimensional Navier-Stokes Equations\n",
    "\n",
    "<!-- @script made by: Kai Chang -->\n",
    "\n",
    "This script takes a deep look into the dataset for 2-dimensional Navier-Stokes equations used in [[Li et al., 2020]](https://arxiv.org/abs/2010.08895) and walks through the implementation of 3-d fourier neural operator. \n",
    "\n",
    "## Problem Statement\n",
    "Here we try to solve\n",
    "\n",
    "\\begin{align}\n",
    "\\partial_t w(x,t) + u(x,t)\\cdot\\nabla w(x,t) &= \\nu\\Delta w(x,t) + f(x) \\quad &x\\in(0,1)\\times(0,1),t\\in(0,T]\\\\\n",
    "\\nabla \\cdot u(x,t) &= 0 \\quad &x\\in(0,1)\\times(0,1),t\\in(0,T]\\\\\n",
    "w(x,0) &= w_0(x) &x\\in(0,1)\\times(0,1)\n",
    "\\end{align}\n",
    "\n",
    "where $u(x,t)$, the velocity field, is a continuous function in $t$ and for each fixed $t$, $u(\\cdot,t)\\in H_{per}^r((0,1)\\times(0,1);\\mathbb{R}^2)$ for any $r > 0$, $w = \\nabla \\times u$ is the vorticity, $w_0 \\in L^2_{per}((0,1)\\times(0,1);\\mathbb{R})$ is the initial vorticity, $\\nu\\in\\mathbb{R}_+$ is the viscosity coefficient, and $f\\in L^2_{per}((0,1)\\times(0,1);\\mathbb{R})$ is the forcing function.\n",
    "\n",
    "## Goal\n",
    "### To learn a operator that maps the vorticity of the first 10 time steps to the vorticity of the next 40 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities import *\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "from timeit import default_timer\n",
    "from Adam import Adam\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNO Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierLayer3d(nn.Module):\n",
    "    \"\"\"\n",
    "    3D Fourier Layer\n",
    "    \n",
    "    ->input => FFT => multiplied by a (kernel) matrix => inverse FFT => add Wv_t => output\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = Parameter(self.scale * torch.rand(in_channels, \n",
    "                                                             out_channels, \n",
    "                                                             self.modes1, \n",
    "                                                             self.modes2, \n",
    "                                                             self.modes3, \n",
    "                                                             dtype=torch.cfloat))\n",
    "        \n",
    "        self.weights2 = Parameter(self.scale * torch.rand(in_channels, \n",
    "                                                             out_channels,\n",
    "                                                             self.modes1,\n",
    "                                                             self.modes2, \n",
    "                                                             self.modes3, \n",
    "                                                             dtype=torch.cfloat))\n",
    "        \n",
    "        self.weights3 = Parameter(self.scale * torch.rand(in_channels,\n",
    "                                                             out_channels,\n",
    "                                                             self.modes1,\n",
    "                                                             self.modes2,\n",
    "                                                             self.modes3, \n",
    "                                                             dtype=torch.cfloat))\n",
    "        \n",
    "        self.weights4 = Parameter(self.scale * torch.rand(in_channels,\n",
    "                                                             out_channels,\n",
    "                                                             self.modes1, \n",
    "                                                             self.modes2, \n",
    "                                                             self.modes3, \n",
    "                                                             dtype=torch.cfloat))\n",
    "        \n",
    "        self.w = nn.Conv3d(in_channels, out_channels, 1)\n",
    "        \n",
    "    # Complex multiplication\n",
    "    def compl_mul3d(self, input, weights):\n",
    "        # (batch, in_channel, x,y,t), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "        return torch.einsum(\"bixyz,ioxyz->boxyz\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfftn(x, dim=[-3,-2,-1])\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        # the reason of out_ft.size(3) = resolution//2 + 1 is because here we are using rfft\n",
    "        # which takes the fact that the DFT of real modes is Hermitian\n",
    "        # Therefore, only half of the entries needs to be stored.\n",
    "        # This is also the reason that we are only doing multiplication half of the usual times\n",
    "        out_ft = torch.zeros(batchsize, \n",
    "                             self.out_channels, \n",
    "                             x.size(-3), \n",
    "                             x.size(-2), \n",
    "                             x.size(-1)//2 + 1, \n",
    "                             dtype=torch.cfloat, \n",
    "                             device=x.device)\n",
    "        \n",
    "        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n",
    "        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n",
    "        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n",
    "\n",
    "        #Return to physical space\n",
    "        x1 = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n",
    "        x2 = self.w(x)\n",
    "        return x1 + x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO3d(nn.Module):\n",
    "    \"\"\"\n",
    "    The overall network.\n",
    "    \n",
    "        1. Lift the input to a higher dimension.\n",
    "        2. 4 Fourier layers\n",
    "        3. Project from the channel space to the output space.\n",
    "        \n",
    "    input: the solution of the first 10 timesteps + 3 locations \n",
    "           (u(1, x, y), ..., u(10, x, y),  x, y, t). \n",
    "           It's a constant function in time, except for the last index.\n",
    "           \n",
    "    input shape: (batchsize, resolution_x, resolution_y, resolution_t, in_channels)\n",
    "        \n",
    "    output: the solution of the next 40 timesteps\n",
    "    output shape: (batchsize, resolution_x, resolution_y, resolution_t, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, modes1, modes2, modes3, width):\n",
    "        super().__init__()\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        self.width = width\n",
    "        self.padding = 6 # pad the domain if input is non-periodic\n",
    "        self.fc0 = nn.Linear(13, self.width)\n",
    "        # the number of input channel is 12\n",
    "        # it contains the solution of the first 10 timesteps + 3 locations \n",
    "        # (u(1,x,y), ..., u(10,x,y),  x, y, t)\n",
    "\n",
    "        self.conv0 = FourierLayer3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv1 = FourierLayer3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv2 = FourierLayer3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv3 = FourierLayer3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "#         self.bn0 = torch.nn.BatchNorm3d(self.width)\n",
    "#         self.bn1 = torch.nn.BatchNorm3d(self.width)\n",
    "#         self.bn2 = torch.nn.BatchNorm3d(self.width)\n",
    "#         self.bn3 = torch.nn.BatchNorm3d(self.width)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "        # shape (batch, resolution_x, resolution_y, resolution_t, T_0 + 3)\n",
    "        \n",
    "        x = self.fc0(x)\n",
    "        # shape (batch, resolution_x, resolution_y, resolution_t, width)\n",
    "        \n",
    "        x = x.permute(0, 4, 1, 2, 3)\n",
    "        # shape (batch, width, resolution_x, resolution_y, resolution_t)\n",
    "        \n",
    "        x = F.pad(x, [0,self.padding]) # pad the domain if input is non-periodic\n",
    "\n",
    "        h1 = self.conv0(x)\n",
    "        x = F.gelu(h1)\n",
    "\n",
    "        h2 = self.conv1(x)\n",
    "        x = F.gelu(h2)\n",
    "\n",
    "        h3 = self.conv1(x)\n",
    "        x = F.gelu(h3)\n",
    "        \n",
    "        h4 = self.conv1(x)\n",
    "        x = h4\n",
    "\n",
    "        x = x[..., :-self.padding] # unpad the domain if input is non-periodic\n",
    "        x = x.permute(0, 2, 3, 4, 1) \n",
    "        # shape (batch, resolution_x, resolution_y, resolution_t, width)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        # shape (batch, resolution_x, resolution_y, resolution_t, 1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n",
    "        # shape (batch, resolution_x, resolution_y, resolution_t, 1); encode x-coordinate\n",
    "        \n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n",
    "        # shape (batch, resolution_x, resolution_y, resolution_t, 1); encode y-coordinate\n",
    "        \n",
    "        gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n",
    "        gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n",
    "        # shape (batch, resolution_x, resolution_y, resolution_t, 1); encode time-index\n",
    "        \n",
    "        return torch.cat((gridx, gridy, gridz), dim=-1).to(device)\n",
    "               # shape (batch, resolution_x, resolution_y, resolution_t, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Let's take a look at the dataset to get us better understand some of the technicalities in the implementation. It contains the solution to 2-d Navier-Stokes equations with different vorticities (curl of the solution). The dataset is generated by classical PDE solvers. The raw data is a dictionary with two keys `'a'` and `'u'`. In neural operator training, `'a'` is the input and `'u'` is the ground truth. \n",
    "\n",
    "In this case, the domain of the map we want to approximate is the space of vorticities up to some time $T_0$; the codomain is the space of vorticities upto some time $T > T_0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['a', 't', 'u']>\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/NS/ns_V1e-3_N5000_T50.mat\"\n",
    "dataloader = MatReader(file_path)\n",
    "print(dataloader.data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time size:  torch.Size([1, 50])\n",
      "a size:  torch.Size([5000, 64, 64, 10])\n",
      "u size:  torch.Size([5000, 64, 64, 40])\n"
     ]
    }
   ],
   "source": [
    "time_data_raw = dataloader.read_field('t')\n",
    "print('time size: ', time_data_raw.size())\n",
    "T_0 = 10\n",
    "T = 50\n",
    "\n",
    "# we note that here the a_data and u_data come from the same tensor. \n",
    "# the difference between them is 'a' is the vorticities at the first 10 time steps\n",
    "# while 'u' is the vorticities at the last 40 time steps\n",
    "# therefore, we are essentially learning a map between the first several time steps and \n",
    "# the last several time steps\n",
    "# i.e. we want to predict the later dynamics given the previous dynamics\n",
    "a_data = dataloader.read_field('u')[:,:,:,:T_0]\n",
    "print('a size: ', a_data.size())\n",
    "u_data = dataloader.read_field('u')[:,:,:,T_0:T]\n",
    "print('u size: ', u_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_train shape:  torch.Size([1000, 64, 64, 40, 10])\n",
      "a_test shape:  torch.Size([200, 64, 64, 40, 10])\n",
      "u_train shape:  torch.Size([1000, 64, 64, 40])\n",
      "u_test shape:  torch.Size([200, 64, 64, 40])\n",
      "preprocessing finished, time used: 4.997746458999998\n"
     ]
    }
   ],
   "source": [
    "n_train = 1000\n",
    "n_test = 200\n",
    "\n",
    "sub_train = 2**0\n",
    "sub_test = 2**0\n",
    "full_res = a_data.size(-2)\n",
    "train_res = full_res // sub_train\n",
    "test_res = full_res // sub_test\n",
    "\n",
    "a_train = a_data[:n_train, ::sub_train, ::sub_train, :]\n",
    "u_train = u_data[:n_train, ::sub_test, ::sub_test, :]\n",
    "a_test = a_data[-n_test:, ::sub_test, ::sub_test, :]\n",
    "u_test = u_data[-n_test:, ::sub_test, ::sub_test, :]\n",
    "\n",
    "runtime = np.zeros(2, )\n",
    "t1 = default_timer()\n",
    "\n",
    "assert (train_res == u_train.shape[-2])\n",
    "assert (T-T_0 == u_train.shape[-1])\n",
    "\n",
    "a_normalizer = UnitGaussianNormalizer(a_train)\n",
    "a_train = a_normalizer.encode(a_train)\n",
    "a_test = a_normalizer.encode(a_test)\n",
    "u_normalizer = UnitGaussianNormalizer(u_train)\n",
    "u_train = u_normalizer.encode(u_train)\n",
    "\n",
    "# stretch the tensor to make size compatible\n",
    "a_train = a_train.reshape(n_train,train_res,train_res,1,T_0).repeat([1,1,1,T-T_0,1])\n",
    "a_test = a_test.reshape(n_test,test_res,test_res,1,T_0).repeat([1,1,1,T-T_0,1])\n",
    "\n",
    "print(\"a_train shape: \", a_train.size())\n",
    "print(\"a_test shape: \", a_test.size())\n",
    "print(\"u_train shape: \", u_train.size())\n",
    "print(\"u_test shape: \", u_test.size())\n",
    "\n",
    "####### load data\n",
    "batch_size = 10\n",
    "batch_size2 = batch_size\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(a_train, u_train),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(a_test, u_test), \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "t2 = default_timer()\n",
    "\n",
    "print('preprocessing finished, time used:', t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing\n",
    "\n",
    "### Input: vorticity of the first $T_0$ (in this case 10) time steps evaluated on some discretized grids of the spatial domain and the grid information\n",
    "\n",
    "### Output: vorticity of the next $T-T_0$ (in this case 40) time steps evaluated on some discretized grids of the spatial domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data resolution:  64\n",
      "testing data resolution:  64\n",
      "6558377\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "###################################################\n",
    "################## model configs ##################\n",
    "###################################################\n",
    "\n",
    "print('training data resolution: ', train_res)\n",
    "print('testing data resolution: ', test_res)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 300\n",
    "epoch_step = 25\n",
    "learning_rate = 0.001\n",
    "step_size = 100\n",
    "gamma = 0.5\n",
    "modes = 8\n",
    "width = 20\n",
    "\n",
    "model = FNO3d(modes, modes, modes, width).to(device)\n",
    "print(count_params(model))\n",
    "\n",
    "optimizer = Adam(model.parameters(), \n",
    "                 lr=learning_rate, \n",
    "                 weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                            step_size=scheduler_step, \n",
    "                                            gamma=gamma)\n",
    "myloss = LpLoss(size_average=False)\n",
    "train_MSE_Loss = []\n",
    "train_L2_Loss = []\n",
    "test_L2_Loss = []\n",
    "\n",
    "####################################################\n",
    "################# plotting configs #################\n",
    "####################################################\n",
    "\n",
    "# change sample by changing rows and cols\n",
    "rows,cols = 2,2\n",
    "num_plots = rows * cols\n",
    "\n",
    "sampled_batch_idx = random.sample(range(n_test//batch_size),num_plots)\n",
    "sampled_plotting_idx = np.random.randint(batch_size, size = num_plots)\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "# config for saving figures\n",
    "saveFig = False\n",
    "fig_folder = 'ep' + str(epochs) + \\\n",
    "             '-lr' + str(learning_rate) + \\\n",
    "             '-decay' + str(gamma) + \\\n",
    "             '-trainRes' + str(train_res) + \\\n",
    "             '-testRes' + str(test_res)\n",
    "\n",
    "fig_dir = '../figs/ns/' + fig_folder\n",
    "if not os.path.isdir(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "plot_pos = 1\n",
    "\n",
    "\n",
    "for ep in range(epochs):\n",
    "    fig.clear()\n",
    "    fig.suptitle('epoch: #' + str(ep),fontsize = 50)\n",
    "    \n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x).view(batch_size, train_res, train_res, T-T_0)\n",
    "\n",
    "        mse = F.mse_loss(out.detach(), y.detach(), reduction='mean')\n",
    "        # mse.backward()\n",
    "\n",
    "        y = u_normalizer.decode(y)\n",
    "        out = u_normalizer.decode(out)\n",
    "        l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "        l2.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_mse += mse.item()\n",
    "        train_l2 += l2.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model(x).view(batch_size, test_res, test_res, T-T_0)\n",
    "            out = u_normalizer.decode(out)\n",
    "            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "            \n",
    "            ##### Plotting #####\n",
    "            if batch in sampled_batch_idx:\n",
    "                idx = sampled_plotting_idx[plot_pos-1]\n",
    "                ax = fig.add_subplot(rows,cols,plot_pos)\n",
    "                ax.clear()\n",
    "#                 ax.get_xaxis().set_visible(False)\n",
    "                ax.set_ylim((-1.2,1.2))\n",
    "                u_sample = out[idx,:,:].reshape((-1,1))\n",
    "                u_sample = u_sample.detach().cpu().numpy()\n",
    "                u_truth = u[idx,:].reshape((-1,1))\n",
    "                u_truth = u_truth.detach().cpu().numpy()\n",
    "                ax.plot(xvals_test, u_sample, 'r', label='FNO1d')\n",
    "                ax.plot(xvals_test, u_truth, 'b--', label='truth')\n",
    "                ax.set_title(f\"sample #{plot_pos}\")\n",
    "                ax.set_xlabel('x')\n",
    "                ax.set_ylabel('u(x,1)')\n",
    "                ax.legend()\n",
    "                plot_pos += 1\n",
    "        fig.canvas.draw()\n",
    "        if saveFig:\n",
    "            if fig_dir[-1] != '/':\n",
    "                fig_dir = fig_dir + '/'\n",
    "            fig_name = fig_dir + 'epoch-' + str(ep) + '.png'\n",
    "            fig.savefig(fig_name)\n",
    "        plot_pos = 1\n",
    "\n",
    "            \n",
    "    # update loss\n",
    "    train_mse /= len(train_loader)\n",
    "    train_MSE_Loss.append(train_mse)\n",
    "    train_l2 /= n_train\n",
    "    train_L2_Loss.append(train_l2)\n",
    "    test_l2 /= n_test\n",
    "    test_L2_Loss.append(test_l2)\n",
    "\n",
    "    t2 = default_timer()\n",
    "    if (ep % epoch_step)==0 or (ep==(epochs-1)):\n",
    "        print('epoch \\t\\t t2-t1 \\t\\t train-MSE-Error \\t train-L2-Error \\t test-L2-Error')\n",
    "        print('{0:d}\\t\\t{1:.5f} \\t\\t {2:.5f}\\t\\t{3:.5f} \\t {4:.5f}' \\\n",
    "              .format(ep, t2-t1, train_mse, train_l2, test_l2))\n",
    "        print('\\n')\n",
    "\n",
    "# pred = torch.zeros(u_test.shape)\n",
    "# index = 0\n",
    "# test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(a_test, u_test),\n",
    "#                                           batch_size=1, \n",
    "#                                           shuffle=False)\n",
    "# with torch.no_grad():\n",
    "#     for x, y in test_loader:\n",
    "#         test_l2 = 0\n",
    "#         x, y = x.to(device), y.to(device)\n",
    "\n",
    "#         out = model(x)\n",
    "#         out = u_normalizer.decode(out)\n",
    "#         pred[index] = out\n",
    "\n",
    "#         test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n",
    "#         print(index, test_l2)\n",
    "#         index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig = False\n",
    "figpath = '../figs/burgers/loss/'\n",
    "figname = 'ep' + str(epochs) + \\\n",
    "          '-lr' + str(learning_rate) + \\\n",
    "          '-decay' + str(gamma) + \\\n",
    "          '-trainRes' + str(train_res) + \\\n",
    "          '-testRes' + str(test_res)\n",
    "\n",
    "figtitle = '1-D Burger\\'s \\n Learning Rate: ' + str(learning_rate) + '\\n' + \\\n",
    "           'Decay Rate: ' + str(gamma) + ' per ' + str(step_size) + ' epochs'\n",
    "plot_loss(figtitle = figtitle,\n",
    "          figpath = figpath, \n",
    "          figname = figname,\n",
    "          savefig = savefig, \n",
    "          train_MSE = train_MSE_Loss, \n",
    "          train_L2 = train_L2_Loss, \n",
    "          test_L2 = test_L2_Loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
