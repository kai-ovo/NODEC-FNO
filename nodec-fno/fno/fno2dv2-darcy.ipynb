{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6c695-bfe9-4f76-a535-bc9daf7ead66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "from timeit import default_timer\n",
    "from utilities import *\n",
    "from Adam import Adam\n",
    "import random\n",
    "from plot_lib import plot_loss, plt_set_default\n",
    "import os\n",
    "\n",
    "plt_set_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13dba7d-1f4e-46f7-a063-408b381ebc7c",
   "metadata": {},
   "source": [
    "## Residual Fourier Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92313a8a-762c-44f4-ab37-203b7830706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierLayer2d(nn.Module):\n",
    "    \"\"\"\n",
    "    2D Fourier layer. \n",
    "    \n",
    "    ->input => FFT => multiplied by a (kernel) matrix => inverse FFT => add Wv_t => output\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = Parameter(self.scale * torch.rand(in_channels, \n",
    "                                                          out_channels, \n",
    "                                                          self.modes1, \n",
    "                                                          self.modes2, \n",
    "                                                          dtype=torch.cfloat))\n",
    "        \n",
    "        self.weights2 = Parameter(self.scale * torch.rand(in_channels, \n",
    "                                                          out_channels, \n",
    "                                                          self.modes1, \n",
    "                                                          self.modes2, \n",
    "                                                          dtype=torch.cfloat))\n",
    "        \n",
    "        self.w = nn.Conv2d(in_channels, out_channels, 1)\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x, y), (in_channel, out_channel, x, y) -> (batch, out_channel, x, y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        # the reason of out_ft.size(3) = resolution//2 + 1 is because here we are using rfft\n",
    "        # which takes the fact that the DFT of real modes is Hermitian\n",
    "        # Therefore, only half of the entries needs to be stored.\n",
    "        # This is also the reason that we are only doing multiplication half of the usual times\n",
    "        out_ft = torch.zeros(batchsize, \n",
    "                             self.out_channels,  \n",
    "                             x.size(-2),\n",
    "                             x.size(-1)//2 + 1,\n",
    "                             dtype=torch.cfloat, \n",
    "                             device=x.device)\n",
    "        \n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        #Return to physical space\n",
    "        x1 = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        x2 = self.w(x)\n",
    "        return x1 + x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69481ff5-44d6-49d5-8f3a-b4d50278eae1",
   "metadata": {},
   "source": [
    "## Residual FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150fe8a-5df9-4047-a8af-fe7f51c3e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, modes1, modes2,  width):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
    "        input shape: (batchsize, x=s, y=s, c=3)\n",
    "        output: the solution \n",
    "        output shape: (batchsize, x=s, y=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        self.padding = 9 # pad the domain if input is non-periodic\n",
    "        self.fc0 = nn.Linear(3, self.width) # input channel is 3: (a(x, y), x, y)\n",
    "\n",
    "        self.conv0 = FourierLayer2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = FourierLayer2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = FourierLayer2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = FourierLayer2d(self.width, self.width, self.modes1, self.modes2)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x.size() = (batch, resolution_x, resolution_y, 1)\n",
    "        \"\"\"\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "        # now shape becomes (batch, resolution_x, resolution_y, 3)\n",
    "        # channel: [a(x,y), x, y]\n",
    "        \n",
    "        x = self.fc0(x)\n",
    "        # now shape becomes (batch, resolution_x, resolution_y, width)\n",
    "        \n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # now shape becomes (batch, width, resolution_x, resolution_y)\n",
    "        \n",
    "#         x = F.pad(x, [0,self.padding, 0,self.padding]) # dataset adopts Dirichlet BC\n",
    "\n",
    "        h1 = self.conv0(x)\n",
    "        x = F.gelu(h1) + x\n",
    "\n",
    "        h2 = self.conv1(x)\n",
    "        x = F.gelu(h2) + x\n",
    "\n",
    "        h3 = self.conv2(x)\n",
    "        x = F.gelu(h3) + x\n",
    "\n",
    "        h4 = self.conv3(x)\n",
    "        x = h4 + x\n",
    "\n",
    "#         x = x[..., :-self.padding, :-self.padding]\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        # now shape becomes (batch, resolution_x, resolution_y, width)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x # x.shape = (batch, resolution_x, resolution_y, 1)\n",
    "    \n",
    "    def get_grid(self, shape, device):\n",
    "        \"\"\"\n",
    "        shape: (batch, resolution_x, resolution_y, 1)\n",
    "        \"\"\"\n",
    "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "        # shape (batch, resolution_x, resolution_y, 1); encode x-coordinate\n",
    "        \n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "        # shape (batch, resolution_x, resolution_y, 1); encode y-coordinate\n",
    "        \n",
    "        return torch.cat((gridx, gridy), dim=-1).to(device) \n",
    "               # shape (batch, resolution_x, resolution_y, 2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e77c74-9012-421b-9655-4c01044871e0",
   "metadata": {},
   "source": [
    "# Training and Testing\n",
    "\n",
    "### Input: diffusion coefficient function $a(x)$ evaluated at some discretized grids of the domain and the location of the grid\n",
    "### Output: solution function $u(x)$ evaluated at some discretized grids (might be different from that of the input) of the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ebd7d-322e-47bd-9968-2f7e634c3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sub = 5\n",
    "test_sub = 5\n",
    "train_res = a_train_raw.size(1)//train_sub + 1\n",
    "test_res = a_test_raw.size(1)//test_sub if a_test_raw.size(1)%test_sub == 0 else a_test_raw.size(1)//test_sub + 1\n",
    "n_train = 1000\n",
    "n_test = 200\n",
    "\n",
    "a_train = a_train_raw[:n_train,::train_sub, ::train_sub]\n",
    "a_test = a_test_raw[:n_test,::test_sub, ::test_sub]\n",
    "u_train = u_train_raw[:n_train,::train_sub, ::train_sub]\n",
    "u_test = u_test_raw[:n_test,::test_sub, ::test_sub]\n",
    "\n",
    "a_normalizer = UnitGaussianNormalizer(a_train)\n",
    "a_train = a_normalizer.encode(a_train)\n",
    "a_test = a_normalizer.encode(a_test)\n",
    "\n",
    "u_normalizer = UnitGaussianNormalizer(u_train)\n",
    "u_train = u_normalizer.encode(u_train)\n",
    "\n",
    "a_train = a_train.reshape(n_train,train_res,train_res,1)\n",
    "a_test = a_test.reshape(n_test,test_res,test_res,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c6a85-c22b-4dec-b5fd-4cbb0c922ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "###################################################\n",
    "################## model configs ##################\n",
    "###################################################\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 20\n",
    "learning_rate = 0.001\n",
    "epochs = 1000\n",
    "\n",
    "# for scheduler's use \n",
    "# for every <step_size> epochs, the learning rate will be multiplied by <gamma>\n",
    "step_size = 250\n",
    "gamma = 0.5\n",
    "modes = 12\n",
    "width = 32\n",
    "\n",
    "model = FNO2d(modes, modes, width).to(device)\n",
    "print(count_params(model))\n",
    "\n",
    "optimizer = Adam(model.parameters(), \n",
    "                 lr=learning_rate, \n",
    "                 weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                            step_size=step_size,\n",
    "                                            gamma=gamma)\n",
    "myloss = LpLoss()#size_average=False) # default is relative L2 norm\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(a_train, u_train), \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(a_test, u_test), \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "train_L2_Loss = []\n",
    "test_L2_Loss = []\n",
    "\n",
    "####################################################\n",
    "################# plotting configs #################\n",
    "####################################################\n",
    "\n",
    "rows,cols = 2,2\n",
    "num_plots = rows * cols\n",
    "num_train_batch = n_train//batch_size\n",
    "num_test_batch = n_test//batch_size\n",
    "assert num_test_batch >= num_plots\n",
    "sampled_batch_idx = random.sample(range(num_test_batch),num_plots)\n",
    "sampled_plotting_idx = np.random.randint(batch_size, size = num_plots)\n",
    "\n",
    "\n",
    "# if true, plot output solution; else plot absolute difference\n",
    "plot_sol = True\n",
    "if plot_sol:\n",
    "    fig_sol = plt.figure(figsize = (16,16))\n",
    "else:  \n",
    "    fig_diff = plt.figure(figsize = (16,16))\n",
    "plot_pos = 1\n",
    "\n",
    "# xlabel = 'training resolution: ' + str(train_res) + '\\n' + \\\n",
    "#          'testing resolution: ' + str(test_res)\n",
    "\n",
    "# config for saving figures\n",
    "saveFigSol = False\n",
    "saveFigDiff = False\n",
    "\n",
    "fig_folder = 'ep' + str(epochs) + \\\n",
    "             '-lr' + \"\".join(str(learning_rate).split('.')) + \\\n",
    "             '-decay' + \"\".join(str(gamma).split('.')) + \\\n",
    "             '-trainRes' + str(train_res) + \\\n",
    "             '-testRes' + str(test_res)\n",
    "\n",
    "fig_dir = '../figs/darcy/' + fig_folder\n",
    "if saveFigDiff or saveFigSol:\n",
    "    if not os.path.isdir(fig_dir):\n",
    "        os.makedirs(fig_dir)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    if plot_sol:\n",
    "        fig_sol.clear()\n",
    "        fig_sol.suptitle('epoch #' + str(ep) + '\\n FNO(a(x))',fontsize = 40)\n",
    "    else:\n",
    "        fig_diff.clear()\n",
    "        fig_diff.suptitle('epoch #' + str(ep) + '\\n |FNO(a(x))-Truth|',fontsize = 40)\n",
    "    \n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_l2 = 0\n",
    "    for batch, (a, u) in enumerate(train_loader):\n",
    "        a, u = a.to(device), u.to(device)\n",
    "        # a.shape = (batch, train_res, train_res, 1)\n",
    "        # u.shape = (batch, train_res, train_res)\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(a).reshape(batch_size, train_res, train_res)\n",
    "        # out.shape = (batch, train_res, train_res, 1)\n",
    "        \n",
    "        out = u_normalizer.decode(out)\n",
    "        u = u_normalizer.decode(u)\n",
    "\n",
    "        loss = myloss(out.view(batch_size,-1), u.view(batch_size,-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_l2 += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch, (a, u) in enumerate(test_loader):\n",
    "            a, u = a.to(device), u.to(device)\n",
    "            # a.shape = (batch, train_res, train_res, 1)\n",
    "            # u.shape = (batch, train_res, train_res)\n",
    "\n",
    "            out = model(a).reshape(batch_size, test_res, test_res)\n",
    "            out = u_normalizer.decode(out)\n",
    "\n",
    "            test_l2 += myloss(out.view(batch_size,-1), u.view(batch_size,-1)).item()\n",
    "            \n",
    "            ### plot sampled testing function ###\n",
    "            if plot_sol:\n",
    "                if batch in sampled_batch_idx:\n",
    "                    idx = sampled_plotting_idx[plot_pos-1]\n",
    "\n",
    "                    # plot outputs of several sampled inputs\n",
    "                    ax = fig_sol.add_subplot(rows,cols,plot_pos)\n",
    "                    ax.clear()\n",
    "                    ax.get_xaxis().set_visible(False)\n",
    "                    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "                    out_sample = out[idx,:,:].reshape((test_res,test_res,1))\n",
    "                    out_sample = out_sample.detach().cpu().numpy()\n",
    "                    ax.set_title(f\"sample #{plot_pos}\")\n",
    "                    ax.imshow(out_sample)\n",
    "#                     plt.colorbar(im)\n",
    "                    \n",
    "                    plot_pos += 1\n",
    "                    \n",
    "            else:\n",
    "                if batch in sampled_batch_idx:\n",
    "                    idx = sampled_plotting_idx[plot_pos-1]\n",
    "                    \n",
    "                    # plot absolute difference between the outputs and ground truth\n",
    "                    ax2 = fig_diff.add_subplot(rows,cols,plot_pos)\n",
    "                    ax2.clear()\n",
    "#                     ax2.get_xaxis().set_visible(False)\n",
    "#                     ax2.get_yaxis().set_visible(False)\n",
    "                    truth_sample = u[idx,:,:].reshape((test_res,test_res,1))\n",
    "                    out_sample = out[idx,:,:].reshape((test_res,test_res,1))\n",
    "                    \n",
    "                    diff_sample = torch.abs(truth_sample.detach() - out_sample.detach()) \\\n",
    "                                  .detach().cpu().numpy()\n",
    "                    im2 = ax2.imshow(diff_sample)\n",
    "                    ax2.set_title(f\"sample #{plot_pos}\")\n",
    "\n",
    "                    plot_pos += 1\n",
    "                    plt.colorbar(im2)\n",
    "        \n",
    "        if plot_sol:\n",
    "            fig_sol.canvas.draw()\n",
    "        else:\n",
    "            fig_diff.canvas.draw()\n",
    "        plot_pos = 1\n",
    "        \n",
    "        if plot_sol and saveFigSol:\n",
    "            if fig_dir[-1] != '/':\n",
    "                fig_dir = fig_dir + '/'\n",
    "            fig_sol_dir = fig_dir + 'sol/'\n",
    "            if not os.path.isdir(fig_sol_dir):\n",
    "                os.makedirs(fig_sol_dir)\n",
    "            fig_sol_name = fig_sol_dir + 'epoch-' + str(ep) + '.png'\n",
    "            fig_sol.savefig(fig_sol_name)\n",
    "        \n",
    "        if (not plot_sol) and saveFigDiff:\n",
    "            if fig_dir[-1] != '/':\n",
    "                fig_dir = fig_dir + '/'\n",
    "            fig_diff_dir = fig_dir + 'diff/'\n",
    "            if not os.path.isdir(fig_diff_dir):\n",
    "                os.makedirs(fig_diff_dir)\n",
    "            fig_diff_name = fig_diff_dir + 'epoch-' + str(ep) + '.png'\n",
    "            fig_diff.savefig(fig_diff_name)\n",
    "        \n",
    "    train_l2 /= num_train_batch\n",
    "    train_L2_Loss.append(train_l2)\n",
    "    \n",
    "    test_l2 /= num_test_batch\n",
    "    test_L2_Loss.append(test_l2)\n",
    "\n",
    "    t2 = default_timer()\n",
    "    if ep%25 == 0 or ep == (epochs-1):\n",
    "        print('epoch \\t\\t t2-t1 \\t\\t train-L2-Error \\t test-L2-Error')\n",
    "        print('{0:d}\\t\\t{1:.5f} \\t\\t{2:.5f} \\t {3:.5f}' \\\n",
    "              .format(ep, t2-t1, train_l2, test_l2))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a421e65-1086-47a8-aa5b-d25b36982907",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveLossFig = False\n",
    "lossfig_path = '../figs/darcy/loss/'\n",
    "lossfig_name = 'ep' + str(epochs) + \\\n",
    "               '-lr' + \"\".join(str(learning_rate).split('.')) + \\\n",
    "               '-decay' + \"\".join(str(gamma).split('.')) + \\\n",
    "               '-trainRes' + str(train_res) + \\\n",
    "               '-testRes' + str(test_res)\n",
    "\n",
    "figtitle = '2-D Darcy Flow \\n Learning Rate: ' + str(learning_rate) + '\\n' + \\\n",
    "           'Decay Rate: ' + str(gamma) + ' per ' + str(step_size) + ' epochs'\n",
    "plot_loss(figtitle = figtitle,\n",
    "          figpath = lossfig_path, \n",
    "          figname = lossfig_name,\n",
    "          savefig = saveLossFig, \n",
    "          train_L2 = train_L2_Loss, \n",
    "          test_L2 = test_L2_Loss)\n",
    "print('minimal relative L2:', min(test_L2_Loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a9283-d714-4469-8f05-f4883cb3eacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
